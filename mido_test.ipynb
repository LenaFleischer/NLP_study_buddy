{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "075dc9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mido import MidiFile, MidiTrack\n",
    "import os\n",
    "from mido import MetaMessage\n",
    "import random\n",
    "\n",
    "# directory name should be midis, at the same level as this file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a6e0dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, track in enumerate(mid.tracks):\n",
    "    print('Track {}: {}'.format(i, track.name))\n",
    "    for msg in track:\n",
    "        if msg.type == 'key_signature':\n",
    "            print(msg)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7298cde-f301-4d3a-b463-0110cd0e0575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will take in a folder and convert each MIDI file into a list of tokens where each token is a note value of the piece\n",
    "# It will return a 2D list where each row is a piece and each column represents a token/note of the piece\n",
    "def tokenize_pieces(midi_folder):\n",
    "    midi_pieces = []\n",
    "    for midi_file_name in os.listdir(midi_folder):\n",
    "        midsource = MidiFile(midi_folder + \"/\" + midi_file_name)\n",
    "        note_token_sequence = []\n",
    "        for i, track in enumerate(midsource.tracks):\n",
    "            if track.name == 'Piano right':\n",
    "                for msg in track:\n",
    "                    if msg.type == 'note_on':\n",
    "                         note_token_sequence.append(msg.note)\n",
    "        midi_pieces.append(note_token_sequence)\n",
    "    return midi_pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3acde28c-f50b-454a-b792-88ac6cc1df4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will generate n grams given a list of token sequences\n",
    "def create_n_grams(n, token_sequences):\n",
    "    \n",
    "    paddings = n - 1\n",
    "    start_padding = \"<start>\"\n",
    "    end_padding = \"<end>\"\n",
    "    n_grams_count = {}\n",
    "\n",
    "    # Add the start padding (<start>) n-1 number of times\n",
    "    if paddings > 0:\n",
    "        for i in range(0, len(token_sequences)):\n",
    "            for j in range(0, paddings):\n",
    "                token_sequences[i].insert(0, start_padding)\n",
    "\n",
    "    # Add the end padding (<end>) once to the end of each sequence\n",
    "    for i in range(0, len(token_sequences)):\n",
    "        token_sequences[i].append(end_padding)\n",
    "\n",
    "    # Iterate through each word in each sequence and using slicing to get the n gram, then add to dictionary/update count\n",
    "    for sequence in token_sequences:\n",
    "        for i in range(len(sequence)-n+1): # Source: https://stackoverflow.com/questions/13423919/computing-n-grams-using-python\n",
    "            gram = sequence[i:i+n] # Source: https://stackoverflow.com/questions/13423919/computing-n-grams-using-python\n",
    "            gram = tuple(gram)\n",
    "            if gram in n_grams_count:\n",
    "                n_grams_count[gram] += 1\n",
    "            else:\n",
    "                n_grams_count[gram] = 1\n",
    "\n",
    "    return n_grams_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7fe03a2b-c848-4b12-8c25-f5b82b8d4a03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Our bigram of notes!\n",
    "song_token_sequences = create_n_grams(2, tokenize_pieces(\"./midis\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b32f8db-d4c4-4301-93b2-f96968e15f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_song(n_gram_frequencies, k):\n",
    "    \n",
    "    # We need to first determine what the \"n\" is from the input frequency dictionary\n",
    "    n = len(tuple(n_gram_frequencies.keys())[0])\n",
    "\n",
    "    # Start with an empty tweet\n",
    "    tweet = []\n",
    "\n",
    "    # For bigrams and up...\n",
    "    if n - 1 > 0:\n",
    "        for i in range(0, n-1):\n",
    "            tweet.insert(0, \"<start>\")\n",
    "    \n",
    "        while tweet[len(tweet)-1] != \"<end>\":\n",
    "            \n",
    "            # Slice the tweet so we can get the previous n-1 gram that comes before the predicted token\n",
    "            previous_token_sequence = tweet[len(tweet)-(n-1):len(tweet)]\n",
    "\n",
    "            # Using dictionary comprehension, create a dictionary containing all n-grams that contain the previous token sequence\n",
    "            matched_dictionary = {k:v for k,v in n_gram_frequencies.items() if k[0:n - 1] == tuple(previous_token_sequence)}\n",
    "\n",
    "            # Prepare a list of possible choices along with their corresponding weights\n",
    "            choices = []\n",
    "            choices_weights = []\n",
    "\n",
    "            # Populate the choices and weights by iterating through the keys in the matched dictionary \n",
    "            matched_dictionary_keylist = list(matched_dictionary.keys())\n",
    "            for j in range(0, len(matched_dictionary_keylist)):\n",
    "                # insert the last word of the tuple key insert it as a choice\n",
    "                choices.append(matched_dictionary_keylist[j][len(matched_dictionary_keylist[j])-1])\n",
    "\n",
    "                # Weights are calculated by taking the actual count of the key and dividing it by all that is found\n",
    "                choices_weights.append(matched_dictionary[matched_dictionary_keylist[j]] / len(matched_dictionary) + k)\n",
    "            \n",
    "            chosen = random.choices(choices, weights=choices_weights, k=1)\n",
    "            tweet.append(chosen[0])\n",
    "    else:\n",
    "        # Special case for unigrams only\n",
    "        choices = []\n",
    "        choices_weights = []\n",
    "        n_gram_frequencies_keylist = list(n_gram_frequencies.keys())\n",
    "        for j in range(0, len(n_gram_frequencies_keylist)):\n",
    "            # insert the last word of the tuple key as a choice\n",
    "            choices.append(n_gram_frequencies_keylist[j][0])\n",
    "            choices_weights.append(n_gram_frequencies[n_gram_frequencies_keylist[j]] / len(n_gram_frequencies) + k)\n",
    "        \n",
    "        # Adding the first item so tweet isn't empty\n",
    "        tweet.append(random.choices(choices, weights=choices_weights, k=1)[0])\n",
    "        while tweet[len(tweet)-1] != \"<end>\":\n",
    "            chosen = random.choices(choices, weights=choices_weights, k=1)\n",
    "            tweet.append(chosen[0])\n",
    "    \n",
    "    # Removing the paddings and converting the grams of the tweet into a string\n",
    "    # return ' '.join([word for word in tweet if word != \"<start>\" and word != \"<end>\"])\n",
    "    tweet.pop(0)\n",
    "    tweet.pop(-1)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f44055c2-6ef5-423c-bc5e-ce6eeb99f6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n",
      "76\n"
     ]
    }
   ],
   "source": [
    "song = generate_song(song_token_sequences, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4d9d5ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dictionary \n",
    "# def createNoteDict(msgs):\n",
    "#     note_dict = {}\n",
    "#     for msg in msgs:\n",
    "#         if msg.type == 'note_on':\n",
    "#             #print(msg.note)\n",
    "#             note = msg.note\n",
    "#             if note in note_dict.keys():\n",
    "#                 note_dict[note] += 1\n",
    "#             else:\n",
    "#                 note_dict[note] = 1    \n",
    "#     sorted_note_dict = sorted(note_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "#     return sorted_note_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
