{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "075dc9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mido import MidiFile, MidiTrack\n",
    "from mido import Message, MidiFile, MidiTrack\n",
    "import os\n",
    "from mido import MetaMessage\n",
    "import random\n",
    "\n",
    "# directory name should be midis, at the same level as this file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a6e0dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, track in enumerate(mid.tracks):\n",
    "    print('Track {}: {}'.format(i, track.name))\n",
    "    for msg in track:\n",
    "        if msg.type == 'key_signature':\n",
    "            print(msg)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7298cde-f301-4d3a-b463-0110cd0e0575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will take in a folder and convert each MIDI file into a list of tokens where each token is a note value of the piece\n",
    "# It will return a 2D list where each row is a piece and each column represents a token/note of the piece\n",
    "def tokenize_pieces(midi_folder):\n",
    "    midi_pieces = []\n",
    "    for midi_file_name in os.listdir(midi_folder):\n",
    "        midsource = MidiFile(midi_folder + \"/\" + midi_file_name)\n",
    "        note_token_sequence = []\n",
    "        for i, track in enumerate(midsource.tracks):\n",
    "            if track.name == 'Piano right':\n",
    "                for msg in track:\n",
    "                    if msg.type == 'note_on':\n",
    "                         note_token_sequence.append(msg.note)\n",
    "        midi_pieces.append(note_token_sequence)\n",
    "    return midi_pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3acde28c-f50b-454a-b792-88ac6cc1df4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will generate n grams given a list of token sequences\n",
    "def create_n_grams(n, token_sequences):\n",
    "    \n",
    "    paddings = n - 1\n",
    "    start_padding = \"<start>\"\n",
    "    end_padding = \"<end>\"\n",
    "    n_grams_count = {}\n",
    "\n",
    "    # Add the start padding (<start>) n-1 number of times\n",
    "    if paddings > 0:\n",
    "        for i in range(0, len(token_sequences)):\n",
    "            for j in range(0, paddings):\n",
    "                token_sequences[i].insert(0, start_padding)\n",
    "\n",
    "    # Add the end padding (<end>) once to the end of each sequence\n",
    "    for i in range(0, len(token_sequences)):\n",
    "        token_sequences[i].append(end_padding)\n",
    "\n",
    "    # Iterate through each word in each sequence and using slicing to get the n gram, then add to dictionary/update count\n",
    "    for sequence in token_sequences:\n",
    "        for i in range(len(sequence)-n+1): # Source: https://stackoverflow.com/questions/13423919/computing-n-grams-using-python\n",
    "            gram = sequence[i:i+n] # Source: https://stackoverflow.com/questions/13423919/computing-n-grams-using-python\n",
    "            gram = tuple(gram)\n",
    "            if gram in n_grams_count:\n",
    "                n_grams_count[gram] += 1\n",
    "            else:\n",
    "                n_grams_count[gram] = 1\n",
    "\n",
    "    return n_grams_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7fe03a2b-c848-4b12-8c25-f5b82b8d4a03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8b32f8db-d4c4-4301-93b2-f96968e15f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_song(n_gram_frequencies, k):\n",
    "    \n",
    "    # We need to first determine what the \"n\" is from the input frequency dictionary\n",
    "    n = len(tuple(n_gram_frequencies.keys())[0])\n",
    "\n",
    "    # Start with an empty tweet\n",
    "    song_sequence = []\n",
    "\n",
    "    # For bigrams and up...\n",
    "    if n - 1 > 0:\n",
    "        for i in range(0, n-1):\n",
    "            song_sequence.insert(0, \"<start>\")\n",
    "    \n",
    "        while song_sequence[len(song_sequence)-1] != \"<end>\":\n",
    "            \n",
    "            # Slice the song so we can get the previous n-1 gram that comes before the predicted token\n",
    "            previous_token_sequence = song_sequence[len(song_sequence)-(n-1):len(song_sequence)]\n",
    "\n",
    "            # Using dictionary comprehension, create a dictionary containing all n-grams that contain the previous token sequence\n",
    "            matched_dictionary = {k:v for k,v in n_gram_frequencies.items() if k[0:n - 1] == tuple(previous_token_sequence)}\n",
    "\n",
    "            # Prepare a list of possible choices along with their corresponding weights\n",
    "            choices = []\n",
    "            choices_weights = []\n",
    "\n",
    "            # Populate the choices and weights by iterating through the keys in the matched dictionary \n",
    "            matched_dictionary_keylist = list(matched_dictionary.keys())\n",
    "            for j in range(0, len(matched_dictionary_keylist)):\n",
    "                # insert the last word of the tuple key insert it as a choice\n",
    "                choices.append(matched_dictionary_keylist[j][len(matched_dictionary_keylist[j])-1])\n",
    "\n",
    "                # Weights are calculated by taking the actual count of the key and dividing it by all that is found\n",
    "                choices_weights.append(matched_dictionary[matched_dictionary_keylist[j]] / len(matched_dictionary) + k)\n",
    "            \n",
    "            chosen = random.choices(choices, weights=choices_weights, k=1)\n",
    "            song_sequence.append(chosen[0])\n",
    "    else:\n",
    "        # Special case for unigrams only\n",
    "        choices = []\n",
    "        choices_weights = []\n",
    "        n_gram_frequencies_keylist = list(n_gram_frequencies.keys())\n",
    "        for j in range(0, len(n_gram_frequencies_keylist)):\n",
    "            # insert the last word of the tuple key as a choice\n",
    "            choices.append(n_gram_frequencies_keylist[j][0])\n",
    "            choices_weights.append(n_gram_frequencies[n_gram_frequencies_keylist[j]] / len(n_gram_frequencies) + k)\n",
    "        \n",
    "        # Adding the first item so tweet isn't empty\n",
    "        song_sequence.append(random.choices(choices, weights=choices_weights, k=1)[0])\n",
    "        while song_sequence[len(song_sequence)-1] != \"<end>\":\n",
    "            chosen = random.choices(choices, weights=choices_weights, k=1)\n",
    "            song_sequence.append(chosen[0])\n",
    "    \n",
    "    # Removing the paddings and converting the grams of the tweet into a string\n",
    "    # return ' '.join([word for word in tweet if word != \"<start>\" and word != \"<end>\"])\n",
    "    for x in range(n-1):\n",
    "        song_sequence.pop(0)\n",
    "    song_sequence.pop(-1)\n",
    "    return song_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f44055c2-6ef5-423c-bc5e-ce6eeb99f6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[79, 84, 80, 82, 80, 79, 80, 79, 77, 74, 74, 76, 74, 72, 70, 69, 70, 69, 70, 74, 72, 70, 69, 70, 69, 70, 74, 69, 72, 65, 69, 57, 70, 58, 74, 62, 60, 72, 64, 59, 62, 64, 61, 59, 62, 60, 64, 67, 72, 76, 67, 79, 74, 68, 79, 80, 74, 68, 76, 80, 64, 69, 76, 69, 77, 71, 69, 59, 62, 68, 61, 57, 66, 61, 64, 57, 53, 65, 45, 57, 57, 45, 51, 48, 50, 45, 49, 45, 48, 57, 53, 57, 57, 57, 59, 57, 52, 54, 64, 52, 56, 62, 53, 56, 57, 61, 64, 63, 67, 64, 68, 72, 71, 69, 67, 67, 62, 66, 69, 74, 72, 72, 65, 68, 77, 77, 65, 72, 62, 74, 59, 71, 67, 67, 67, 60, 48, 55, 52, 60, 50, 59, 55, 54, 55, 59, 62, 65, 63, 66, 61, 65, 66, 64, 66, 64, 66, 67, 60, 68, 60, 69, 76, 65, 67, 71, 74, 67, 67, 72, 72, 71, 69, 62, 65, 69, 67, 70, 69, 67, 74, 64, 62, 71, 60, 69, 59, 67, 57, 65, 64, 60, 55, 59, 62, 66, 56, 61, 59, 68, 66, 57, 68, 59, 56, 66, 59, 68, 59, 56, 66, 59, 68, 59, 64, 71, 71, 64, 59, 60, 82, 83, 88, 83, 80, 71, 68, 65, 65, 77, 71, 72, 74, 76, 77, 69, 67, 73, 74, 72, 71, 69, 67, 66, 67, 69, 71, 72, 71, 72, 69, 67, 64, 60, 60, 52, 53, 62, 54, 55, 62, 62, 62, 63, 62, 54, 60, 51, 58, 50, 58, 53, 60, 55, 62, 60, 67, 52, 62, 60, 67, 55, 67, 55, 60, 67, 55, 55, 60, 63, 69, 55, 55, 59, 62, 67, 55, 63, 62, 60, 55, 60, 59, 62, 60, 66, 74, 58, 70, 62, 60, 66, 67, 66, 67, 70, 72, 76, 74, 72, 71, 72, 71, 72, 69, 66, 67, 67, 72, 72, 67, 60, 64, 64, 62, 66, 67, 59, 65, 64, 61, 63, 60, 63, 60, 63, 61, 60, 58, 56, 51, 52, 64, 51, 63, 50, 48, 63, 51, 56, 60, 50, 54, 60, 62, 50, 59, 62, 83, 79, 74, 98, 95, 91, 88, 92, 89, 101, 98, 94, 91, 95, 88, 96, 95, 83, 88, 93, 92, 90, 88, 86, 84, 83, 81, 79, 77, 76, 74, 72, 72, 76, 76, 72, 67]\n"
     ]
    }
   ],
   "source": [
    "# Our bigram of notes!\n",
    "song_token_sequences = create_n_grams(4, tokenize_pieces(\"./midis\"))\n",
    "song = generate_song(song_token_sequences, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "22757bf3-20f4-49a2-acc2-ac3fa169e44f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d74ed28e-8533-4d0a-908d-5eee695b8b19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cea2d8-711e-419c-b40c-6a4818aefc23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
